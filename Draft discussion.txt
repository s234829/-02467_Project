Draft discussion:

Things we would like to improve, or things that would be interesting for future analysis:

The data analysis itself was hampered somewhat by the sparsity of the dataset. Many of the Movies lacked proper titles, images and genres which made it impossible to do a comprehensive study on the entire dataset. This also pushed the bias on content to physical medias which had the most detailed metadata attached. To get an even better sense of consumer behavior and the structure of real movie review tendencies we would need to use all available Movies and find a way to match the ASIN data with images and most importantly proper titles. Additionally, finding a way to normalize all the movie titles across versions and consolidating reviews/metadata would improve the quality of the dataset. Since a lot of movies come in different permutations, in box sets or on different formats. The network we ended up using was specific to physical media from the Amazon marketplace - having access or including data from other sites or streaming platforms would probably give much deeper insights and interesting communities. But the methodology to utilize network science to create recommendations remains the same.

It would also be interesting to look at more centrality measures in conjunction with a larger dataset to find more highly influential titles, and have them community specific to create gateway candidates directly.

The analysis was also limited since we needed to make a judgement to use the dominant genre in each category, where most had 2 or 3 genres that were fairly high on the list.  

Many improvements could have been made to the code and dataset from the start in hindsight:

We should have tried to formalize the genre whitelist as it's own category item in the dataset which would have cleaned up a lot of the code. In other words, make a separate column for the genres after scraping the categories column. With this we could also look at inputting more genres from separate databases using available titles. 

Ethically, algorithmic recommendation systems need to be fair and balanced - but a common theme with content services are exploitative algorithms to maximize profit and retention. Our goal is to explore graphs in order to make more intelligent systems that behave with the users best interests in mind by simply providing the highest quality, and most relevant title based on the users preferences. However, common practices will steer the user towards content that is designed to simply have the user spend more time on the platform at the expense of relevance and quality. Creating networks tailored only to investigate how to get users sucked into your platform - we would consider a predatory dark pattern that goes against the essence of the project. Such considerations should therefore play a part when conducting these analysis or deploying social science in the real world. 










